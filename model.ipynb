{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Datasets and Get Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(\"Dataset\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")\n",
    "\n",
    "bean_class = len(os.listdir(\"Dataset/train\"))\n",
    "\n",
    "dataset_dir = pathlib.Path(\"Dataset/train\")\n",
    "class_names = np.array(sorted([item.name for item in dataset_dir.glob(\"*\")]))\n",
    "print(class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "])\n",
    "\n",
    "image_dataset = datasets.ImageFolder(root='Dataset/train/',transform=resize_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show image example in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes of your dataset\n",
    "classes = image_dataset.classes\n",
    "\n",
    "# Create a figure with subplots for each class\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "\n",
    "# Loop through each class and plot the first image\n",
    "for i, cls in enumerate(classes):\n",
    "    # Get the indices of the images for this class\n",
    "    indices = [j for j, (x, y) in enumerate(image_dataset) if y == i]\n",
    "    # Get the first image for this class\n",
    "    img = image_dataset[indices[0]][0]\n",
    "    img = img.resize((256,256))\n",
    "    # Plot the image on the corresponding subplot\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(cls)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image, _ = image_dataset[0]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(example_image)\n",
    "ax[0].set_title('Before transform')\n",
    "transformed_image = transform(example_image)\n",
    "ax[1].imshow(transformed_image.permute(1, 2, 0))\n",
    "ax[1].set_title('After transform')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50 Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "batch_size = 64\n",
    "num_epochs = 64\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply preprocessing to transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.ImageFolder(root='Dataset/train/', transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_set = datasets.ImageFolder(root='Dataset/val/', transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_set = datasets.ImageFolder(root='Dataset/test/', transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load pre-trained ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers in the pre-trained model\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the last fully connected layer with a new one\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet50.fc.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "# Iterate over the validation dataset in batches\n",
    "train_predictions = np.array([])\n",
    "train_ground_truths = np.array([])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    resnet50.train()\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = resnet50(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_losses.append(train_loss/train_total)\n",
    "    train_accs.append(train_correct/train_total)\n",
    "    \n",
    "    # Validation\n",
    "    resnet50.eval()\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            outputs = resnet50(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            train_predictions = np.concatenate((train_predictions, predicted.cpu().numpy()))\n",
    "            train_ground_truths = np.concatenate((train_ground_truths, labels.cpu().numpy()))\n",
    "\n",
    "            \n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # remove the extra predictions\n",
    "        if len(train_predictions) > len(train_ground_truths):\n",
    "            train_predictions = train_predictions[:len(train_ground_truths)]\n",
    "\n",
    "    # Convert predictions and true labels to numpy arrays\n",
    "    train_predictions = np.array(train_predictions)\n",
    "    train_ground_truths = np.array(train_ground_truths)\n",
    "    \n",
    "    val_losses.append(val_loss/val_total)\n",
    "    val_accs.append(val_correct/val_total)\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "          .format(epoch+1, num_epochs, train_losses[-1], train_accs[-1], val_losses[-1], val_accs[-1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot losses and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accs, label='Train Acc')\n",
    "plt.plot(val_accs, label='Val Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train_ground_truths, train_predictions)\n",
    "labels_category = ['Dark' 'Green' 'Light' 'Medium']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels= labels_category, yticklabels=labels_category)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "resnet50.eval()\n",
    "\n",
    "# Keep track of the validation loss and accuracy\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the validation dataset in batches\n",
    "test_predictions = []\n",
    "test_ground_truths = []\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    # Forward pass\n",
    "    outputs = resnet50(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Update the validation loss\n",
    "    test_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    test_predictions.extend(predicted.cpu().numpy())\n",
    "    test_ground_truths.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Update the testing accuracy\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    test_total += labels.size(0)\n",
    "    test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute the average testing loss and accuracy\n",
    "test_loss /= len(test_set)\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "# Print the testing loss and accuracy\n",
    "print(f'Testing loss: {test_loss:.4f}, accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(test_ground_truths, test_predictions)\n",
    "labels_category = ['Dark' 'Green' 'Light' 'Medium']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels= labels_category, yticklabels=labels_category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
